{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this Notebook, we are going to try to predict what makes a song popular using:\n",
    "### Vanilla Tree Based Models\n",
    "### Bagged Tree Based Models\n",
    "### Plus, Ensembling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis we will use a dataset of roughly ~470 songs to determine what makes a song popular.\n",
    "\n",
    "Dataset: The dataset found on kaggle (https://www.kaggle.com/leonardopena/top-spotify-songs-from-20102019-by-year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, this is a great resource on what a Decision Tree is and how to utilize sklearn to build one in Python\n",
    "\n",
    "https://towardsdatascience.com/decision-tree-in-python-b433ae57fb93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO \n",
    "from IPython.display import Image \n",
    "import pydotplus\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv(\"/Users/samlafell/Desktop/Desktop-Samâ€™s_MacBook_Pro/MSA/Kaggle/Top_50_Spotify/top10s.csv\",encoding='iso-8859-1').drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>top genre</th>\n",
       "      <th>year</th>\n",
       "      <th>bpm</th>\n",
       "      <th>nrgy</th>\n",
       "      <th>dnce</th>\n",
       "      <th>dB</th>\n",
       "      <th>live</th>\n",
       "      <th>val</th>\n",
       "      <th>dur</th>\n",
       "      <th>acous</th>\n",
       "      <th>spch</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hey, Soul Sister</td>\n",
       "      <td>Train</td>\n",
       "      <td>neo mellow</td>\n",
       "      <td>2010</td>\n",
       "      <td>97</td>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "      <td>-4</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>217</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Love The Way You Lie</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>detroit hip hop</td>\n",
       "      <td>2010</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "      <td>75</td>\n",
       "      <td>-5</td>\n",
       "      <td>52</td>\n",
       "      <td>64</td>\n",
       "      <td>263</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TiK ToK</td>\n",
       "      <td>Kesha</td>\n",
       "      <td>dance pop</td>\n",
       "      <td>2010</td>\n",
       "      <td>120</td>\n",
       "      <td>84</td>\n",
       "      <td>76</td>\n",
       "      <td>-3</td>\n",
       "      <td>29</td>\n",
       "      <td>71</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Bad Romance</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>dance pop</td>\n",
       "      <td>2010</td>\n",
       "      <td>119</td>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>-4</td>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just the Way You Are</td>\n",
       "      <td>Bruno Mars</td>\n",
       "      <td>pop</td>\n",
       "      <td>2010</td>\n",
       "      <td>109</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>-5</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>221</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title      artist        top genre  year  bpm  nrgy  dnce  \\\n",
       "0      Hey, Soul Sister       Train       neo mellow  2010   97    89    67   \n",
       "1  Love The Way You Lie      Eminem  detroit hip hop  2010   87    93    75   \n",
       "2               TiK ToK       Kesha        dance pop  2010  120    84    76   \n",
       "3           Bad Romance   Lady Gaga        dance pop  2010  119    92    70   \n",
       "4  Just the Way You Are  Bruno Mars              pop  2010  109    84    64   \n",
       "\n",
       "   dB  live  val  dur  acous  spch  pop  \n",
       "0  -4     8   80  217     19     4   83  \n",
       "1  -5    52   64  263     24    23   82  \n",
       "2  -3    29   71  200     10    14   80  \n",
       "3  -4     8   71  295      0     4   79  \n",
       "4  -5     9   43  221      2     4   78  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>bpm</th>\n",
       "      <th>nrgy</th>\n",
       "      <th>dnce</th>\n",
       "      <th>dB</th>\n",
       "      <th>live</th>\n",
       "      <th>val</th>\n",
       "      <th>dur</th>\n",
       "      <th>acous</th>\n",
       "      <th>spch</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>603.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2014.592040</td>\n",
       "      <td>118.545605</td>\n",
       "      <td>70.504146</td>\n",
       "      <td>64.379768</td>\n",
       "      <td>-5.578773</td>\n",
       "      <td>17.774461</td>\n",
       "      <td>52.225539</td>\n",
       "      <td>224.674959</td>\n",
       "      <td>14.326700</td>\n",
       "      <td>8.358209</td>\n",
       "      <td>66.520730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.607057</td>\n",
       "      <td>24.795358</td>\n",
       "      <td>16.310664</td>\n",
       "      <td>13.378718</td>\n",
       "      <td>2.798020</td>\n",
       "      <td>13.102543</td>\n",
       "      <td>22.513020</td>\n",
       "      <td>34.130059</td>\n",
       "      <td>20.766165</td>\n",
       "      <td>7.483162</td>\n",
       "      <td>14.517746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>239.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>424.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year         bpm        nrgy        dnce          dB  \\\n",
       "count   603.000000  603.000000  603.000000  603.000000  603.000000   \n",
       "mean   2014.592040  118.545605   70.504146   64.379768   -5.578773   \n",
       "std       2.607057   24.795358   16.310664   13.378718    2.798020   \n",
       "min    2010.000000    0.000000    0.000000    0.000000  -60.000000   \n",
       "25%    2013.000000  100.000000   61.000000   57.000000   -6.000000   \n",
       "50%    2015.000000  120.000000   74.000000   66.000000   -5.000000   \n",
       "75%    2017.000000  129.000000   82.000000   73.000000   -4.000000   \n",
       "max    2019.000000  206.000000   98.000000   97.000000   -2.000000   \n",
       "\n",
       "             live         val         dur       acous        spch         pop  \n",
       "count  603.000000  603.000000  603.000000  603.000000  603.000000  603.000000  \n",
       "mean    17.774461   52.225539  224.674959   14.326700    8.358209   66.520730  \n",
       "std     13.102543   22.513020   34.130059   20.766165    7.483162   14.517746  \n",
       "min      0.000000    0.000000  134.000000    0.000000    0.000000    0.000000  \n",
       "25%      9.000000   35.000000  202.000000    2.000000    4.000000   60.000000  \n",
       "50%     12.000000   52.000000  221.000000    6.000000    5.000000   69.000000  \n",
       "75%     24.000000   69.000000  239.500000   17.000000    9.000000   76.000000  \n",
       "max     74.000000   98.000000  424.000000   99.000000   48.000000   99.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the article as a guide, we are able to look at multiple levels of song popularity.\n",
    "\n",
    "## Applying that to our specific problem, we are going to split the 'pop' variable into 0-3. This will split our popularity variable into 25% quantiles. We will assume 0 is not popular and 3 is the most popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pd.qcut to cut based on the quantile (4 for using the quantiles)\n",
    "df['pop_model'] = pd.qcut(df['pop'],\n",
    "                              q=4,\n",
    "                              labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Feature and Target dataframes\n",
    "X = df.select_dtypes('number').iloc[:, 1:-2]\n",
    "y = df.select_dtypes('number').iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummies for the level of features\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dt, out_file=dot_data, feature_names=X_train.columns)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())\n",
    "\n",
    "# That is a deep tree!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  8, 10, 13],\n",
       "       [12, 10,  4, 10],\n",
       "       [11, 11,  9, 10],\n",
       "       [ 8,  8,  6, 10]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the confusion matrix of this single decision tree\n",
    "popularity = np.array(y_test).argmax(axis=1)\n",
    "predictions = np.array(y_pred).argmax(axis=1)\n",
    "confusion_matrix(popularity, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_correct = 0\n",
    "for i in range(0,4):\n",
    "    sum_correct += confusion_matrix(popularity, predictions)[i][i]\n",
    "\n",
    "accuracy = sum_correct / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26490066225165565"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at this, our Decision Tree was just slightly better than completely random. It correctly classified 26.5% of observations with 4 possible buckets. Completely random you would expect roughly ~25%.\n",
    "\n",
    "## How can we improve this? Bagging!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@rrfd/boosting-bagging-and-stacking-ensemble-methods-with-sklearn-and-mlens-a455c0c982de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To use the cross-validation, we need our y-Train to be 1 column\n",
    "X = df.select_dtypes('number').iloc[:, 1:-2]\n",
    "y = df.select_dtypes('number').iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Accuracy of the 10-fold Cross Validation on Decision Trees is 0.2968\n",
      "The Mean Accuracy of the 10-fold Cross Validation on Bagged Trees is 0.3103\n",
      "\n",
      "\n",
      "Did Bagged Trees Perform Better?\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Classifier and get one of the methods to work!\n",
    "# For Cross-Validation, use all the data instead of splitting\n",
    "np.random.seed(1234)\n",
    "dt = DecisionTreeClassifier()\n",
    "vanilla_scores = cross_val_score(dt, X, y, cv=10, n_jobs=-1)\n",
    "bagging_clf = BaggingClassifier(dt, max_samples=0.4, max_features=9, random_state=1234)\n",
    "bagging_scores = cross_val_score(bagging_clf, X, y, cv=10, n_jobs=-1)\n",
    "\n",
    "print('The Mean Accuracy of the 10-fold Cross Validation on Decision Trees is', round(np.mean(vanilla_scores),4))\n",
    "print('The Mean Accuracy of the 10-fold Cross Validation on Bagged Trees is', round(np.mean(bagging_scores),4))\n",
    "print('\\n')\n",
    "print('Did Bagged Trees Perform Better?')\n",
    "if np.mean(bagging_scores) > np.mean(vanilla_scores):\n",
    "    print('Yes')\n",
    "elif np.mean(bagging_scores) < np.mean(vanilla_scores):\n",
    "    print('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of: 0.337, std: (+/-) 0.042 [RandomForestClassifier]\n",
      "Mean of: 0.320, std: (+/-) 0.047 [Bagging RandomForestClassifier]\n",
      "\n",
      "Mean of: 0.327, std: (+/-) 0.038 [ExtraTreesClassifier]\n",
      "Mean of: 0.346, std: (+/-) 0.049 [Bagging ExtraTreesClassifier]\n",
      "\n",
      "Mean of: 0.288, std: (+/-) 0.059 [KNeighborsClassifier]\n",
      "Mean of: 0.285, std: (+/-) 0.023 [Bagging KNeighborsClassifier]\n",
      "\n",
      "Mean of: 0.298, std: (+/-) 0.013 [SVC]\n",
      "Mean of: 0.277, std: (+/-) 0.017 [Bagging SVC]\n",
      "\n",
      "Mean of: 0.295, std: (+/-) 0.043 [RidgeClassifier]\n",
      "Mean of: 0.292, std: (+/-) 0.047 [Bagging RidgeClassifier]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get some classifiers to evaluate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Create classifiers\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "et = ExtraTreesClassifier(n_estimators=50)\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC(gamma='auto')\n",
    "rg = RidgeClassifier()\n",
    "\n",
    "clf_array = [rf, et, knn, svc, rg]\n",
    "\n",
    "for clf in clf_array:\n",
    "    vanilla_scores = cross_val_score(clf, X, y, cv=10, n_jobs=-1)\n",
    "    bagging_clf = BaggingClassifier(clf, max_samples=0.4, max_features=X.shape[1], random_state=1234)\n",
    "    bagging_scores = cross_val_score(bagging_clf, X, y, cv=10, n_jobs=-1)\n",
    "    \n",
    "    print(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [{0}]\"\n",
    "    .format(clf.__class__.__name__,\n",
    "            vanilla_scores.mean(),\n",
    "            vanilla_scores.std()))\n",
    "    print(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\"\n",
    "          .format(clf.__class__.__name__,\n",
    "                  bagging_scores.mean(),\n",
    "                  bagging_scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, bagging generally worked better on Decision Trees, but it looks like bagging actually did not work better for us on any of the other methods we try here.\n",
    "\n",
    "## Random Forest Performs the best. Up to 34.6% accuracy from our initial 26.49% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37 (+/- 0.03) [Random Forest]\n",
      "Accuracy: 0.37 (+/- 0.06) [Extra Trees]\n",
      "Accuracy: 0.29 (+/- 0.06) [KNeighbors]\n",
      "Accuracy: 0.30 (+/- 0.01) [SVC]\n",
      "Accuracy: 0.30 (+/- 0.04) [Ridge Classifier]\n",
      "Accuracy: 0.33 (+/- 0.06) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# Example of hard voting \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "clf = [rf, et, knn, svc, rg]\n",
    "eclf = VotingClassifier(estimators=[('Random Forests', rf), ('Extra Trees', et), ('KNeighbors', knn), ('SVC', svc), ('Ridge Classifier', rg)], voting='hard')\n",
    "for clf, label in zip([rf, et, knn, svc, rg, eclf], ['Random Forest', 'Extra Trees', 'KNeighbors', 'SVC', 'Ridge Classifier', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In comparing, we are doing great with Random Forest. Let's keep it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Accuracy of the 10-fold Cross Validation on Random Forest is 0.3616\n",
      "The Mean Accuracy of the 10-fold Cross Validation on Bagged Random Forest is 0.3204\n",
      "\n",
      "\n",
      "Did Bagged Forest Perform Better?\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Classifier and get one of the methods to work!\n",
    "# For Cross-Validation, use all the data instead of splitting\n",
    "np.random.seed(1234)\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "vanilla_scores = cross_val_score(rf, X, y, cv=10, n_jobs=-1)\n",
    "bagging_clf = BaggingClassifier(rf, max_samples=0.4, max_features=9, random_state=1234)\n",
    "bagging_scores = cross_val_score(bagging_clf, X, y, cv=10, n_jobs=-1)\n",
    "\n",
    "print('The Mean Accuracy of the 10-fold Cross Validation on Random Forest is', round(np.mean(vanilla_scores),4))\n",
    "print('The Mean Accuracy of the 10-fold Cross Validation on Bagged Random Forest is', round(np.mean(bagging_scores),4))\n",
    "print('\\n')\n",
    "print('Did Bagged Forest Perform Better?')\n",
    "if np.mean(bagging_scores) > np.mean(vanilla_scores):\n",
    "    print('Yes')\n",
    "elif np.mean(bagging_scores) < np.mean(vanilla_scores):\n",
    "    print('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3714759535655058"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "y_pred = cross_val_predict(rf, X, y, cv=10)\n",
    "\n",
    "# Create the confusion matrix of this single decision tree\n",
    "popularity = np.array(y)\n",
    "predictions = np.array(y_pred)\n",
    "\n",
    "sum_correct = 0\n",
    "for i in range(0,4):\n",
    "    sum_correct += confusion_matrix(popularity, predictions)[i][i]\n",
    "\n",
    "accuracy = sum_correct / len(X)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We were able to find that Random Forest performed better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>val</td>\n",
       "      <td>0.131089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nrgy</td>\n",
       "      <td>0.130343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dur</td>\n",
       "      <td>0.124311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dnce</td>\n",
       "      <td>0.124153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bpm</td>\n",
       "      <td>0.121921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>acous</td>\n",
       "      <td>0.110939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>live</td>\n",
       "      <td>0.105752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spch</td>\n",
       "      <td>0.087952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dB</td>\n",
       "      <td>0.063541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "val    0.131089\n",
       "nrgy   0.130343\n",
       "dur    0.124311\n",
       "dnce   0.124153\n",
       "bpm    0.121921\n",
       "acous  0.110939\n",
       "live   0.105752\n",
       "spch   0.087952\n",
       "dB     0.063541"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp_df = pd.DataFrame(clf.feature_importances_).T\n",
    "feature_imp_df.columns = X.columns\n",
    "feature_imp_df.T.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this example, we looked at how well a Decision Tree did, and then moved into focusing more on the impacts of Vanilla vs. Bagging Models.\n",
    "\n",
    "### There is a lot of literature out there about Bagging/Boosting/Strapped models. Each one has their advantages and disadvantages.\n",
    "\n",
    "### This dataset seems to inherently have a lot of noise, as I've discovered through previous analysis. Thus, it's hard to make conclusions\n",
    "\n",
    "### The Random Forest determined Valence to be the most important factor in determining the popularity of song.\n",
    "\n",
    "### Although, nothing in this analysis was particularly strong. Since this was our most accurate model out of the candidate models, we begin to get a sense that if we know how 'happy' a song is perceived to be, we might know better where to place it in terms of popularity.\n",
    "\n",
    "### Again, this is a weak correlation, and would not by any means say that happier songs are more popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
